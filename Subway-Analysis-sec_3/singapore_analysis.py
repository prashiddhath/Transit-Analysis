# -*- coding: utf-8 -*-
"""Singapore_Evaluation (metro - mrt & lrt only).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SF2KTw2wHQoGKaGxRkfikHZpThHzd-hr
"""

pip install folium

import os, zipfile, pandas as pd

# path to your file (adjust if your notebook isn't in your home directory)
zip_path = os.path.expanduser("~/Downloads/gtfs-feed-lta.zip")
extract_dir = "gtfs_lta"

# unzip the GTFS feed
with zipfile.ZipFile(zip_path, "r") as z:
    z.extractall(extract_dir)

# list all extracted files
os.listdir(extract_dir)

# ================================
# Load libraries
# ================================
import pandas as pd
import os

# ================================
# Path to extracted GTFS folder
# ================================
extract_dir = "gtfs_lta"

# ================================
# Load routes file (KEY FILE)
# ================================
routes = pd.read_csv(os.path.join(extract_dir, "routes.txt"))

# ================================
# Inspect structure
# ================================
routes.columns

# ======================================================
# Filter GTFS to Metro / Train ONLY (MRT + LRT)
# ======================================================
# GTFS route_type meanings:
# 1 = Metro (MRT)
# 2 = Rail / Train (LRT)
# 3 = Bus

# 1. Filter routes
metro_routes = routes[routes["route_type"].isin([1, 2])]
print(f"METRO ROUTES — {metro_routes.shape[0]} rows")

# 2. Filter trips
metro_trips = trips[trips["route_id"].isin(metro_routes["route_id"])]
print(f"METRO TRIPS — {metro_trips.shape[0]} rows")

# 3. Filter stop_times
metro_stop_times = stop_times[
    stop_times["trip_id"].isin(metro_trips["trip_id"])
]
print(f"METRO STOP_TIMES — {metro_stop_times.shape[0]} rows")

# 4. Filter stops (stations)
metro_stops = stops[
    stops["stop_id"].isin(metro_stop_times["stop_id"])
]
print(f"METRO STOPS — {metro_stops.shape[0]} rows")

# Preview (Metro only)
display(metro_routes.head())
display(metro_trips.head())
display(metro_stop_times.head())
display(metro_stops.head())

"""## Preprocessing"""

# === Basic cleaning & formatting for consistency (METRO ONLY) ===
import numpy as np

# Drop duplicates
metro_stops.drop_duplicates(inplace=True)
metro_routes.drop_duplicates(inplace=True)
metro_trips.drop_duplicates(inplace=True)
metro_stop_times.drop_duplicates(inplace=True)

# Remove invalid coordinate rows
metro_stops = metro_stops.dropna(subset=["stop_lat", "stop_lon"])
metro_stops = metro_stops.query("1.2 <= stop_lat <= 1.5 and 103.5 <= stop_lon <= 104.2")

# Ensure consistent datatypes
metro_stops["stop_lat"] = metro_stops["stop_lat"].astype(float)
metro_stops["stop_lon"] = metro_stops["stop_lon"].astype(float)
metro_routes["route_id"] = metro_routes["route_id"].astype(str)
metro_trips["trip_id"] = metro_trips["trip_id"].astype(str)
metro_stop_times["trip_id"] = metro_stop_times["trip_id"].astype(str)

# Standardize column names
metro_stops.columns = metro_stops.columns.str.lower()
metro_routes.columns = metro_routes.columns.str.lower()
metro_trips.columns = metro_trips.columns.str.lower()
metro_stop_times.columns = metro_stop_times.columns.str.lower()

# Check for orphaned records
invalid_trips = metro_trips[~metro_trips["route_id"].isin(metro_routes["route_id"])]
invalid_stop_times = metro_stop_times[~metro_stop_times["trip_id"].isin(metro_trips["trip_id"])]
print(f"Invalid trips: {len(invalid_trips)}, Invalid stop_times: {len(invalid_stop_times)}")

# Remove orphaned rows
metro_stop_times = metro_stop_times[
    metro_stop_times["trip_id"].isin(metro_trips["trip_id"])
]
metro_trips = metro_trips[
    metro_trips["route_id"].isin(metro_routes["route_id"])
]

# Handle missing stop names
metro_stops["stop_name"] = metro_stops["stop_name"].fillna("Unknown Stop")

# Convert time columns to seconds
def to_seconds(t):
    try:
        h, m, s = map(int, str(t).split(":"))
        return h * 3600 + m * 60 + s
    except Exception:
        return np.nan

metro_stop_times["arrival_secs"] = metro_stop_times["arrival_time"].apply(to_seconds)
metro_stop_times["departure_secs"] = metro_stop_times["departure_time"].apply(to_seconds)

print("✅ Metro-only preprocessing complete.")

"""## Analysis"""

# ================================
# Analysis: Singapore MRT / LRT
# ================================

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")

# --------------------------------
# Summary statistics
# --------------------------------
print("Unique metro routes:", metro_routes["route_id"].nunique())
print("Unique metro trips:", metro_trips["trip_id"].nunique())
print("Unique metro stops:", metro_stops["stop_id"].nunique())

# --------------------------------
# Trips per route
# --------------------------------
trips_per_route = (
    metro_trips.groupby("route_id")["trip_id"]
    .nunique()
    .reset_index(name="trip_count")
    .merge(
        metro_routes[["route_id", "route_short_name", "route_long_name"]],
        on="route_id",
        how="left"
    )
    .sort_values("trip_count", ascending=False)
)

plt.figure(figsize=(9, 4))
sns.barplot(
    data=trips_per_route,
    x="route_short_name",
    y="trip_count",
    palette="crest"
)
plt.title("Trips per MRT/LRT Line")
plt.xlabel("Line")
plt.ylabel("Number of Trips")
plt.tight_layout()
plt.show()

# --------------------------------
# Stops per trip
# --------------------------------
stops_per_trip = (
    metro_stop_times.groupby("trip_id")["stop_sequence"]
    .max()
    .reset_index(name="num_stops")
)

print("Stops per trip summary:")
print(stops_per_trip["num_stops"].describe())

plt.figure(figsize=(7, 4))
sns.histplot(stops_per_trip["num_stops"], bins=25, color="skyblue")
plt.title("Distribution of Stops per MRT/LRT Trip")
plt.xlabel("Stops per Trip")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# --------------------------------
# Geographic distribution of MRT stations
# --------------------------------
plt.figure(figsize=(6, 6))
plt.scatter(
    metro_stops["stop_lon"],
    metro_stops["stop_lat"],
    s=12,
    alpha=0.7
)
plt.title("Geographic Distribution of MRT/LRT Stations in Singapore")
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.tight_layout()
plt.show()

# --------------------------------
# Stop usage frequency
# --------------------------------
stop_freq = (
    metro_stop_times["stop_id"]
    .value_counts()
    .reset_index()
)
stop_freq.columns = ["stop_id", "count"]

top_stops = stop_freq.head(10).merge(
    metro_stops[["stop_id", "stop_name"]],
    on="stop_id",
    how="left"
)

print("Top 10 most frequently served MRT/LRT stations:")
display(top_stops)

# --------------------------------
# Temporal analysis: service window
# --------------------------------
earliest_dep = metro_stop_times["departure_secs"].min()
latest_dep = metro_stop_times["departure_secs"].max()

print(
    f"Service window (approx): "
    f"{earliest_dep/3600:.1f}h to {latest_dep/3600:.1f}h"
)

# --------------------------------
# Service frequency per hour
# --------------------------------
metro_stop_times["hour"] = (
    metro_stop_times["departure_secs"] // 3600
).astype(int)

hourly = metro_stop_times["hour"].value_counts().sort_index()

plt.figure(figsize=(8, 4))
plt.plot(hourly.index, hourly.values, marker="o")
plt.title("MRT/LRT Departures per Hour")
plt.xlabel("Hour of Day")
plt.ylabel("Number of Departures")
plt.xticks(range(0, 25))
plt.tight_layout()
plt.show()

"""## Further Analysis

### Build a stop-level graph from GTFS
"""

import pandas as pd
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_theme()

# ======================================================
# Further Analysis: Stop-level MRT / LRT Network
# ======================================================

import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
import folium

sns.set_theme()

# --------------------------------
# Build stop-level directed graph
# --------------------------------
G = nx.DiGraph()  # MRT is directional

# Add MRT/LRT stations as nodes
for _, row in metro_stops.iterrows():
    G.add_node(
        row["stop_id"],
        name=row.get("stop_name", ""),
        lat=row.get("stop_lat", np.nan),
        lon=row.get("stop_lon", np.nan)
    )

# Sort stop_times so trips are in order
metro_stop_times_sorted = metro_stop_times.sort_values(
    ["trip_id", "stop_sequence"]
)

# Create edges from consecutive stops in the same trip
edges = []
prev_trip = None
prev_stop = None

for _, r in metro_stop_times_sorted.iterrows():
    trip = r["trip_id"]
    curr_stop = r["stop_id"]

    if trip == prev_trip and prev_stop is not None:
        edges.append((prev_stop, curr_stop, trip))

    prev_trip = trip
    prev_stop = curr_stop

# Add edges to graph
for u, v, trip_id in edges:
    route_id = metro_trips.loc[
        metro_trips["trip_id"] == trip_id, "route_id"
    ].iloc[0]

    if G.has_edge(u, v):
        G[u][v]["trips"].add(trip_id)
        G[u][v]["routes"].add(route_id)
    else:
        G.add_edge(
            u,
            v,
            weight=1,
            trips={trip_id},
            routes={route_id}
        )

print(
    f"Graph built: {G.number_of_nodes()} MRT/LRT stops, "
    f"{G.number_of_edges()} directed edges"
)

# --------------------------------
# Map of MRT/LRT stations (sample)
# --------------------------------
m = folium.Map(
    location=[
        metro_stops["stop_lat"].mean(),
        metro_stops["stop_lon"].mean()
    ],
    zoom_start=11
)

for _, r in metro_stops.sample(min(200, len(metro_stops))).iterrows():
    folium.CircleMarker(
        [r["stop_lat"], r["stop_lon"]],
        radius=3,
        color="blue",
        fill=True,
        fill_opacity=0.6
    ).add_to(m)

m

# --------------------------------
# Top connected MRT/LRT stations
# --------------------------------
deg = dict(G.degree())
top_nodes = sorted(deg, key=deg.get, reverse=True)[:100]

H = G.subgraph(top_nodes)

pos = {
    n: (G.nodes[n]["lon"], G.nodes[n]["lat"])
    for n in H.nodes()
}

plt.figure(figsize=(8, 6))
nx.draw(
    H,
    pos,
    node_size=30,
    node_color="tomato",
    edge_color="gray",
    with_labels=False
)
plt.title("Top 100 Most Connected MRT/LRT Stations")
plt.tight_layout()
plt.show()



"""### Efficiency metrics"""

# --- Degree distribution (MRT / LRT only) ---
deg = dict(G.degree())   # G is the MRT/LRT-only graph
deg_series = pd.Series(deg)

plt.figure(figsize=(6,4))
sns.histplot(deg_series, bins=20)
plt.title("MRT/LRT Station Degree Distribution")
plt.xlabel("Degree (in + out)")
plt.ylabel("Number of Stations")
plt.tight_layout()
plt.show()

print("Average degree:", deg_series.mean())
print("Maximum degree:", deg_series.max())

# --- Path-length efficiency on MRT/LRT network ---
if not nx.is_weakly_connected(G):
    largest_cc = max(nx.weakly_connected_components(G), key=len)
    H = G.subgraph(largest_cc).copy()
else:
    H = G

print("Stations in giant component:", H.number_of_nodes())

nodes = list(H.nodes())
sample_nodes = np.random.choice(
    nodes,
    size=min(100, len(nodes)),   # smaller sample is sufficient
    replace=False
)

all_lengths = []
for s in sample_nodes:
    sp = nx.single_source_shortest_path_length(H, s, cutoff=40)
    all_lengths.extend(sp.values())

avg_path_len = np.mean(all_lengths)
print(f"Approx. average shortest-path length (hops): {avg_path_len:.2f}")

# --- Stops per MRT/LRT trip ---
stops_per_trip = (
    metro_stop_times
    .groupby("trip_id")["stop_sequence"]
    .max()
)

plt.figure(figsize=(6,4))
sns.histplot(stops_per_trip, bins=20)
plt.title("Distribution of Stops per MRT/LRT Trip")
plt.xlabel("Stops per Trip")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

"""### Resilience simulations"""

# === Node importance: betweenness centrality (MRT / LRT only) ===

# Use MRT/LRT-only graph (H is giant component of metro graph)
betw = nx.betweenness_centrality(
    H,
    k=min(50, H.number_of_nodes()),   # smaller sample for MRT network
    normalized=True,
    seed=42
)

betw_series = pd.Series(betw).sort_values(ascending=False)
top_20_hubs = betw_series.head(20)

print("Top 20 MRT/LRT stations by betweenness centrality:")
display(top_20_hubs)

# === Resilience simulations (MRT / LRT network) ===

def largest_component_size(graph):
    if isinstance(graph, nx.DiGraph):
        comps = nx.weakly_connected_components(graph)
    else:
        comps = nx.connected_components(graph)
    return max(len(c) for c in comps)

def simulate_removal(graph, nodes_to_remove):
    Gcopy = graph.copy()
    sizes = []
    for n in nodes_to_remove:
        if n in Gcopy:
            Gcopy.remove_node(n)
        sizes.append(largest_component_size(Gcopy))
    return sizes

# number of nodes to remove
k = min(20, H.number_of_nodes())

# targeted attack (high betweenness)
top_nodes = list(top_20_hubs.index)[:k]
targeted_sizes = simulate_removal(H, top_nodes)

# random attack
rng = np.random.default_rng(42)
random_nodes = rng.choice(list(H.nodes()), size=k, replace=False)
random_sizes = simulate_removal(H, random_nodes)

# plot
plt.figure(figsize=(7,4))
plt.plot(range(1, k+1), targeted_sizes, label="Remove high-betweenness stations")
plt.plot(range(1, k+1), random_sizes, label="Remove random stations")
plt.xlabel("Number of removed stations")
plt.ylabel("Size of largest connected component")
plt.title("Resilience of Singapore MRT/LRT Network")
plt.legend()
plt.tight_layout()
plt.show()



"""### Equity Access"""

# === Equity access: MRT / LRT spatial accessibility ===

# use METRO stops only
min_lat, max_lat = metro_stops["stop_lat"].min(), metro_stops["stop_lat"].max()
min_lon, max_lon = metro_stops["stop_lon"].min(), metro_stops["stop_lon"].max()

lat_grid = np.linspace(min_lat, max_lat, 40)
lon_grid = np.linspace(min_lon, max_lon, 40)

grid_results = []

for lat in lat_grid:
    for lon in lon_grid:
        # naive lat/lon Euclidean distance (OK for SG scale)
        dist = np.sqrt(
            (metro_stops["stop_lat"] - lat) ** 2 +
            (metro_stops["stop_lon"] - lon) ** 2
        )

        # stations within ~300m (~0.003 degrees)
        served = (dist < 0.003).sum()
        grid_results.append((lat, lon, served))

access_df = pd.DataFrame(grid_results, columns=["lat", "lon", "served"])

plt.figure(figsize=(6,5))
sc = plt.scatter(
    access_df["lon"],
    access_df["lat"],
    c=access_df["served"],
    s=35
)
plt.colorbar(sc, label="MRT/LRT stations within ~300m")
plt.title("MRT/LRT Accessibility Proxy (Singapore)")
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.tight_layout()
plt.show()



"""### Helper to “Compare cities” (Berlin, NYC)"""

def build_graph_from_gtfs(stops, stop_times, trips):
    G = nx.DiGraph()
    for _, row in stops.iterrows():
        G.add_node(row["stop_id"],
                   name=row.get("stop_name",""),
                   lat=row.get("stop_lat", np.nan),
                   lon=row.get("stop_lon", np.nan))
    sts = stop_times.sort_values(["trip_id","stop_sequence"])
    prev_trip = None
    prev_stop = None
    for _, r in sts.iterrows():
        trip = r["trip_id"]; stopid = r["stop_id"]
        if trip == prev_trip and prev_stop is not None:
            route_id = trips.loc[trips["trip_id"] == trip, "route_id"].iloc[0]
            if not G.has_edge(prev_stop, stopid):
                G.add_edge(prev_stop, stopid,
                           routes={route_id})
        prev_trip = trip
        prev_stop = stopid
    return G

def summarize_network(G, name="city"):
    if not nx.is_weakly_connected(G):
        H = G.subgraph(max(nx.weakly_connected_components(G), key=len)).copy()
    else:
        H = G
    # sample paths
    nodes_list = list(H.nodes())
    sample_nodes = np.random.choice(nodes_list, size=min(150, len(nodes_list)), replace=False)
    all_lengths = []
    for s in sample_nodes:
        sp = nx.single_source_shortest_path_length(H, s, cutoff=40)
        all_lengths.extend(sp.values())
    print(f"{name}: nodes={G.number_of_nodes()}, edges={G.number_of_edges()}, "
          f"avg_path={np.mean(all_lengths):.2f}")

# usage later:
# G_sg = build_graph_from_gtfs(stops_sg, stop_times_sg, trips_sg)
# summarize_network(G_sg, "Singapore")
# (then NYC, then Berlin)



