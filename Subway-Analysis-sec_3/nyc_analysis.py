# -*- coding: utf-8 -*-
"""NYCAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RJyqFN3D3tqzXQk3sowZzkmIGv2YNTca
"""

import os, zipfile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ====== PATHS ======
ZIP_PATH = "/content/drive/MyDrive/gtfs_subway.zip"
EXTRACT_DIR = "/content/nyc_gtfs_subway"

os.makedirs(EXTRACT_DIR, exist_ok=True)

# Unzip once
if not os.path.exists(os.path.join(EXTRACT_DIR, "routes.txt")):
    with zipfile.ZipFile(ZIP_PATH, "r") as z:
        z.extractall(EXTRACT_DIR)

# Load GTFS
routes = pd.read_csv(os.path.join(EXTRACT_DIR, "routes.txt"))
trips = pd.read_csv(os.path.join(EXTRACT_DIR, "trips.txt"))
stop_times = pd.read_csv(os.path.join(EXTRACT_DIR, "stop_times.txt"))
stops = pd.read_csv(os.path.join(EXTRACT_DIR, "stops.txt"))

print("Loaded:")
print("  routes:", routes.shape)
print("  trips:", trips.shape)
print("  stop_times:", stop_times.shape)
print("  stops:", stops.shape)

# ====== EXCLUSIONS (partner) ======
EXCLUDE_ROUTE_IDS = {"6X", "7X", "FX", "SI"}  # SI is route_id; short name often shows SIR
EXCLUDE_SHORT_NAMES = {"6X", "7X", "FX", "SIR"}  # catch Staten Island Railway short name

routes["route_id"] = routes["route_id"].astype(str)
routes["route_short_name"] = routes["route_short_name"].astype(str)

excluded = routes[
    routes["route_id"].isin(EXCLUDE_ROUTE_IDS) |
    routes["route_short_name"].isin(EXCLUDE_SHORT_NAMES)
][["route_id", "route_short_name", "route_long_name"]].copy()

print("\nExcluded routes found in feed (route_id / route_short_name / route_long_name):")
if len(excluded):
    print(excluded.to_string(index=False))
else:
    print("  (none found; check route_id / route_short_name values)")

routes_f = routes[
    ~(routes["route_id"].isin(EXCLUDE_ROUTE_IDS) | routes["route_short_name"].isin(EXCLUDE_SHORT_NAMES))
].copy()

# Cascade filter trips -> stop_times -> stops
trips_f = trips[trips["route_id"].isin(routes_f["route_id"])].copy()
stop_times_f = stop_times[stop_times["trip_id"].isin(trips_f["trip_id"])].copy()
stops_f = stops[stops["stop_id"].isin(stop_times_f["stop_id"].unique())].copy()

print("\nAfter exclusion + cascading filters:")
print("  Lines (routes):", routes_f.shape[0])
print("  Trips:", trips_f.shape[0])
print("  Stops used:", stops_f.shape[0])

print("\nRemaining line labels (route_short_name):")
print(sorted(routes_f["route_short_name"].unique()))

def clean_stop_name(name: str) -> str:
    if not isinstance(name, str):
        return ""
    # remove parenthetical platform notes if they exist
    if "(" in name:
        name = name.split("(")[0].strip()
    return name.strip()

stops_f["parent_station"] = stops_f.get("parent_station", pd.Series([np.nan]*len(stops_f)))
stops_f["parent_station"] = stops_f["parent_station"].astype(str)

# If parent_station is missing/blank, fall back to cleaned stop_name
station_key = []
for _, r in stops_f.iterrows():
    ps = r.get("parent_station", "")
    if ps and ps != "nan":
        station_key.append(ps)
    else:
        station_key.append(clean_stop_name(r.get("stop_name", "")))

stops_f["station_key"] = station_key

stations_df = (
    stops_f.groupby("station_key", as_index=False)
    .agg(
        station_name=("stop_name", lambda s: clean_stop_name(min(s, key=lambda x: len(str(x))))),
        station_lat=("stop_lat", "mean"),
        station_lon=("stop_lon", "mean"),
        platforms=("stop_id", "nunique"),
    )
)

# map stop_id -> station_key
stop_to_station = stops_f.set_index("stop_id")["station_key"].to_dict()

print("Unique station complexes:", stations_df.shape[0])
stations_df.head()

# Merge stop_times with route
st_times_route = stop_times_f.merge(trips_f[["trip_id", "route_id"]], on="trip_id", how="left")
st_times_route["station_key"] = st_times_route["stop_id"].map(stop_to_station)

# Trips per line
trips_per_line = trips_f.merge(routes_f[["route_id", "route_short_name"]], on="route_id", how="left")
trips_per_line = trips_per_line.groupby("route_short_name")["trip_id"].nunique().sort_values(ascending=False)

# Stations served per line (unique station complexes)
stations_per_line = (
    st_times_route.merge(routes_f[["route_id", "route_short_name"]], on="route_id", how="left")
    .groupby("route_short_name")["station_key"].nunique()
    .sort_values(ascending=False)
)

# Lines per station (transfer-ish measure)
lines_per_station = (
    st_times_route.merge(routes_f[["route_id", "route_short_name"]], on="route_id", how="left")
    .groupby("station_key")["route_short_name"].nunique()
    .sort_values(ascending=False)
)

print("\n=== NYC Subway (GTFS) Summary ===")
print("Lines (after exclusions):", routes_f.shape[0])
print("Trips:", trips_f["trip_id"].nunique())
print("Stop records:", stop_times_f.shape[0])
print("Stops (platforms) used:", stops_f["stop_id"].nunique())
print("Unique stations (complexes):", stations_df.shape[0])

print("\nTop 15 lines by trips:")
print(trips_per_line.head(15).to_string())

print("\nTop 15 lines by unique stations served:")
print(stations_per_line.head(15).to_string())

print("\nTop 15 stations by # lines serving them:")
top_station_keys = lines_per_station.head(15).index.tolist()
top_station_names = stations_df.set_index("station_key").loc[top_station_keys, "station_name"]
print(pd.DataFrame({"station": top_station_names.values, "lines": lines_per_station.head(15).values}).to_string(index=False))


# ---- Plot: station scatter ----
plt.figure(figsize=(7,7))
plt.scatter(stations_df["station_lon"], stations_df["station_lat"], s=8, alpha=0.8)
plt.gca().set_aspect("equal", adjustable="box")
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("NYC Subway Stations (Unique Station Complexes)\nExcluded: 6X, 7X, FX, SI/SIR")
plt.show()

# ---- Plot: trips per line ----
plt.figure(figsize=(10,4))
trips_per_line.plot(kind="bar")
plt.ylabel("Trip count")
plt.title("Trips per Line (GTFS)")
plt.tight_layout()
plt.show()

# ---- Plot: stations per line ----
plt.figure(figsize=(10,4))
stations_per_line.plot(kind="bar")
plt.ylabel("Unique station complexes")
plt.title("Stations Served per Line (GTFS)")
plt.tight_layout()
plt.show()

# ---- Plot: lines per station distribution ----
plt.figure(figsize=(6,4))
plt.hist(lines_per_station.values, bins=range(1, int(lines_per_station.max())+2), align="left")
plt.xlabel("# Lines serving station")
plt.ylabel("# Stations")
plt.title("Distribution: Lines per Station")
plt.tight_layout()
plt.show()

def parse_time_to_minutes(t):
    # GTFS allows 24+ hours, keep it valid
    h, m, s = t.split(":")
    return int(h)*60 + int(m) + int(s)/60

# Pick the dominant service_id (most trips) if present
if "service_id" in trips_f.columns:
    dominant_service = trips_f["service_id"].value_counts().idxmax()
    trips_svc = trips_f[trips_f["service_id"] == dominant_service].copy()
else:
    dominant_service = None
    trips_svc = trips_f.copy()

st_svc = stop_times_f[stop_times_f["trip_id"].isin(trips_svc["trip_id"])].copy()
st_svc = st_svc.merge(trips_svc[["trip_id", "route_id"]], on="trip_id", how="left")
st_svc = st_svc.merge(routes_f[["route_id", "route_short_name"]], on="route_id", how="left")

# Ensure time columns exist (MTA GTFS usually has arrival_time/departure_time)
time_col_start = "departure_time" if "departure_time" in st_svc.columns else "arrival_time"
time_col_end = "arrival_time" if "arrival_time" in st_svc.columns else "departure_time"

st_svc = st_svc.dropna(subset=[time_col_start, time_col_end])

st_svc["t_start"] = st_svc[time_col_start].astype(str).apply(parse_time_to_minutes)
st_svc["t_end"]   = st_svc[time_col_end].astype(str).apply(parse_time_to_minutes)

span = (
    st_svc.groupby("route_short_name")
    .agg(first_min=("t_start","min"), last_min=("t_end","max"), trips=("trip_id","nunique"))
    .sort_values("first_min")
)

def fmt_hhmm(x):
    h = int(x//60)
    m = int(x%60)
    return f"{h:02d}:{m:02d}"

span["first"] = span["first_min"].apply(fmt_hhmm)
span["last"] = span["last_min"].apply(fmt_hhmm)

print("\nDominant service_id used:", dominant_service)
print(span[["first","last","trips"]].to_string())

import folium
from folium.plugins import HeatMap

center_lat = stops_f["stop_lat"].mean()
center_lon = stops_f["stop_lon"].mean()

m_heat = folium.Map(location=[center_lat, center_lon], zoom_start=11)

heat_points = stops_f[["stop_lat", "stop_lon"]].values.tolist()
HeatMap(heat_points, radius=10, blur=14).add_to(m_heat)

m_heat

import matplotlib.pyplot as plt

plt.figure(figsize=(7,6))
plt.hexbin(stops_f["stop_lon"], stops_f["stop_lat"], gridsize=45)
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("NYC Subway Stop Density (Hexbin)")
plt.gca().set_aspect("equal", adjustable="box")
plt.tight_layout()
plt.show()

import numpy as np
from collections import defaultdict

def clean_station_name(name: str) -> str:
    name = str(name)
    if "(" in name:
        name = name.split("(")[0].strip()
    return name.strip()

# --- build station complexes from stops_f ---
groups = defaultdict(list)
for _, r in stops_f.iterrows():
    groups[clean_station_name(r["stop_name"])].append(r)

stations = []
stop_to_station = {}
for sid, (k, rows) in enumerate(groups.items()):
    lats = [float(x["stop_lat"]) for x in rows]
    lons = [float(x["stop_lon"]) for x in rows]
    stop_ids = [str(x["stop_id"]) for x in rows]

    stations.append({
        "station_id": sid,
        "station_name": k,
        "lat": float(np.mean(lats)),
        "lon": float(np.mean(lons)),
        "stop_ids": stop_ids
    })
    for stid in stop_ids:
        stop_to_station[stid] = sid

stations_df = pd.DataFrame(stations)

# --- map station -> lines served (using your filtered trips_f/stop_times_f) ---
station_lines = defaultdict(set)

st_tmp = stop_times_f.copy()
st_tmp["stop_id"] = st_tmp["stop_id"].astype(str)
st_tmp = st_tmp.merge(trips_f[["trip_id","route_id"]], on="trip_id", how="left")

for _, row in st_tmp.iterrows():
    sid = stop_to_station.get(row["stop_id"])
    if sid is not None:
        station_lines[sid].add(row["route_id"])

stations_df["num_lines"] = stations_df["station_id"].map(lambda x: len(station_lines.get(x, set())))
print("Station complexes:", len(stations_df))
print("Transfer-ish (2+ lines):", (stations_df["num_lines"] >= 2).sum())

m_bubble = folium.Map(location=[stations_df["lat"].mean(), stations_df["lon"].mean()], zoom_start=11)

minL, maxL = stations_df["num_lines"].min(), stations_df["num_lines"].max()

def scale_radius(val, vmin, vmax, rmin=3, rmax=14):
    if vmax == vmin:
        return (rmin + rmax)/2
    return rmin + (rmax - rmin) * (val - vmin) / (vmax - vmin)

for _, r in stations_df.iterrows():
    rad = scale_radius(r["num_lines"], minL, maxL)
    folium.CircleMarker(
        location=[r["lat"], r["lon"]],
        radius=rad,
        popup=f"{r['station_name']} | lines={int(r['num_lines'])}",
        fill=True,
        fill_opacity=0.7
    ).add_to(m_bubble)

m_bubble

top_hubs = stations_df.sort_values("num_lines", ascending=False).head(15)

plt.figure(figsize=(10,5))
plt.bar(top_hubs["station_name"], top_hubs["num_lines"])
plt.xticks(rotation=70, ha="right")
plt.ylabel("# of lines serving station")
plt.title("Top 15 NYC Subway Transfer Hubs (by lines served)")
plt.tight_layout()
plt.show()